{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c91e4b-3070-474e-95a2-f0003c142b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# get spark session\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# import packages\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pyspark.pandas as ps\n",
    "import numpy as np\n",
    "from timeit import timeit\n",
    "import gc\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import array_max\n",
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.pandas.config import set_option, reset_option\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyspark.sql.types import (\n",
    "    DateType, DoubleType, FloatType, IntegerType, StringType, StructField, StructType\n",
    ")\n",
    "\n",
    "# import self-defined module\n",
    "import module.time_split_cv as time_split_cv\n",
    "\n",
    "# set conf\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", True)\n",
    "ps.set_option(\"compute.default_index_type\", \"distributed\")\n",
    "set_option(\"compute.ops_on_diff_frames\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e8b217-eb88-4a2c-b987-390e99f995be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8526c70b-1ac2-4506-860f-f3475f4f7595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'800'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.shuffle.partitions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc1559-ed4a-477a-aa0d-80cd045a5db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2fbc63-82d8-4d8c-a5d8-27c06ce87c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get argument\n",
    "# TRAIN_PERIOD = int(sys.argv[1])\n",
    "# print(f\"\\n\\n \\\n",
    "# \t==================================================\\n \\\n",
    "# \t========= TRAIN_PERIOD = {TRAIN_PERIOD} =========\\n \\\n",
    "# \t==================================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe3a0ce-ddd8-42e8-a219-10e992977147",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERIOD = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e02ba11-b92d-4b6a-b91b-8d079a33d46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 105:==================================================>(2022 + 2) / 2024]77]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "     ==================================================\n",
      "     ===== df.rdd.getNumPartitions() = 23 ===========\n",
      "     ==================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "     ==================================================\n",
      "     ===== 5. Train SVD model by pandas_UDF ===========\n",
      "     ==================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 126:====================================================>  (22 + 1) / 23]7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "     ==================================================\n",
      "     ===== results.rdd.getNumPartitions() = 364 ===========\n",
      "     ==================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "     ==================================================\n",
      "     ===== 6. Save result table to parquet ============\n",
      "     ==================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 17:35:46,301 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 144.0 (TID 14287) (bdse75.example.com executor 5): org.apache.spark.SparkException: Task failed while writing rows.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:500)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:321)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 603, in main\n",
      "    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n",
      "    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n",
      "    f, return_type = read_command(pickleSer, infile)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n",
      "    command = serializer._read_with_length(file)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n",
      "    return self.loads(obj)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n",
      "    return pickle.loads(obj, encoding=encoding)\n",
      "ModuleNotFoundError: No module named 'module'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:91)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:304)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:311)\n",
      "\t... 9 more\n",
      "\n",
      "2022-04-10 17:36:04,331 WARN scheduler.TaskSetManager: Lost task 0.3 in stage 144.0 (TID 14290) (bdse75.example.com executor 5): org.apache.spark.SparkException: Task failed while writing rows.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:500)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:321)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 603, in main\n",
      "    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n",
      "    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n",
      "    f, return_type = read_command(pickleSer, infile)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n",
      "    command = serializer._read_with_length(file)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n",
      "    return self.loads(obj)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n",
      "    return pickle.loads(obj, encoding=encoding)\n",
      "ModuleNotFoundError: No module named 'module'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:91)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:304)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:311)\n",
      "\t... 9 more\n",
      "\n",
      "2022-04-10 17:36:04,332 ERROR scheduler.TaskSetManager: Task 0 in stage 144.0 failed 4 times; aborting job\n",
      "2022-04-10 17:36:04,339 ERROR datasources.FileFormatWriter: Aborting job 216f289f-b615-4a27-85e6-ac085e356a5c.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 144.0 failed 4 times, most recent failure: Lost task 0.3 in stage 144.0 (TID 14290) (bdse75.example.com executor 5): org.apache.spark.SparkException: Task failed while writing rows.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:500)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:321)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 603, in main\n",
      "    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n",
      "    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n",
      "    f, return_type = read_command(pickleSer, infile)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n",
      "    command = serializer._read_with_length(file)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n",
      "    return self.loads(obj)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n",
      "    return pickle.loads(obj, encoding=encoding)\n",
      "ModuleNotFoundError: No module named 'module'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:91)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:304)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:311)\n",
      "\t... 9 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:218)\n",
      "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:110)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:110)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:106)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:106)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:93)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:91)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:128)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:781)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.SparkException: Task failed while writing rows.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:500)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:321)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 603, in main\n",
      "    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n",
      "    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n",
      "    f, return_type = read_command(pickleSer, infile)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n",
      "    command = serializer._read_with_length(file)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n",
      "    return self.loads(obj)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n",
      "    return pickle.loads(obj, encoding=encoding)\n",
      "ModuleNotFoundError: No module named 'module'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:91)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:304)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:311)\n",
      "\t... 9 more\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o4916.parquet.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.jobAbortedError(QueryExecutionErrors.scala:496)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:251)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:110)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:110)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:106)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:106)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:93)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:91)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:128)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:781)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 144.0 failed 4 times, most recent failure: Lost task 0.3 in stage 144.0 (TID 14290) (bdse75.example.com executor 5): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:500)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:321)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 603, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n    command = serializer._read_with_length(file)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n    return self.loads(obj)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n    return pickle.loads(obj, encoding=encoding)\nModuleNotFoundError: No module named 'module'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:91)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:304)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:311)\n\t... 9 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:218)\n\t... 42 more\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:500)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:321)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 603, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n    command = serializer._read_with_length(file)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n    return self.loads(obj)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n    return pickle.loads(obj, encoding=encoding)\nModuleNotFoundError: No module named 'module'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:91)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:304)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:311)\n\t... 9 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124m    ==================================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124m    ===== results.rdd.getNumPartitions() = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults\u001b[38;5;241m.\u001b[39mrdd\u001b[38;5;241m.\u001b[39mgetNumPartitions()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===========\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124m    ==================================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124m    ==================================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124m    ===== 6. Save result table to parquet ============\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124m    ==================================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoalesce\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/user/HM_parquet/SVD_model/params/para\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mTRAIN_PERIOD\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124m    ==================================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124m    =====================  存檔完成 ===================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124m    ==================================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:885\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m--> 885\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o4916.parquet.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.jobAbortedError(QueryExecutionErrors.scala:496)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:251)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:110)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:110)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:106)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:106)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:93)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:91)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:128)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:781)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 144.0 failed 4 times, most recent failure: Lost task 0.3 in stage 144.0 (TID 14290) (bdse75.example.com executor 5): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:500)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:321)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 603, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n    command = serializer._read_with_length(file)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n    return self.loads(obj)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n    return pickle.loads(obj, encoding=encoding)\nModuleNotFoundError: No module named 'module'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:91)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:304)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:311)\n\t... 9 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:218)\n\t... 42 more\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:500)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:321)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 603, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n    command = serializer._read_with_length(file)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n    return self.loads(obj)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n    return pickle.loads(obj, encoding=encoding)\nModuleNotFoundError: No module named 'module'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.writeWithIterator(FileFormatDataWriter.scala:91)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:304)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:311)\n\t... 9 more\n"
     ]
    }
   ],
   "source": [
    "# def main(TRAIN_PERIOD):\n",
    "# print(f\"\\n\\n \\\n",
    "#     ==================================================\\n \\\n",
    "#     ================== 1. Load data ==================\\n \\\n",
    "#     ==================================================\\n\\n\")\n",
    "tran_ps = ps.read_parquet('/user/HM_parquet/transactions_train.parquet').drop(['price', 'sales_channel_id'], axis=1)\n",
    "\n",
    "tran_ps.set_index('t_dat',inplace=True)\n",
    "tran_ps['start_test'] = ''\n",
    "tran_ps['split_id'] = ''\n",
    "\n",
    "# print(f\"\\n\\n \\\n",
    "#     ==================================================\\n \\\n",
    "#     ======= 2. Split and concat data by time =========\\n \\\n",
    "#     ==================================================\\n\\n\")\n",
    "split_data, split_id = time_split_cv.split(tran_ps,train_period=TRAIN_PERIOD,test_period=7,stride=30,show_progress=False)\n",
    "split_data.reset_index(inplace=True)\n",
    "del tran_ps\n",
    "\n",
    "\n",
    "# print(f\"\\n\\n \\\n",
    "#     ==================================================\\n \\\n",
    "#     ===== 3.Parameter grid table cross split_id ======\\n \\\n",
    "#     ==================================================\\n\\n\")\n",
    "para_cross_split = time_split_cv.make_para_cross_split_table(split_id)\n",
    "\n",
    "# print(f\"\\n\\n \\\n",
    "#     ==================================================\\n \\\n",
    "#     ===== 4. Join split_data parameter grid table ====\\n \\\n",
    "#     ==================================================\\n\\n\")\n",
    "\n",
    "join_data = split_data.join(para_cross_split.set_index('split_id'), on='split_id')\n",
    "# join_data.set_index('t_dat',inplace=True)\n",
    "join_data['train_period'] = TRAIN_PERIOD\n",
    "\n",
    "del split_data, para_cross_split\n",
    "df = join_data.to_spark()\n",
    "del join_data\n",
    "\n",
    "print(f\"\\n\\n \\\n",
    "    ==================================================\\n \\\n",
    "    ===== df.rdd.getNumPartitions() = {df.rdd.getNumPartitions()} ===========\\n \\\n",
    "    ==================================================\\n\\n\")\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\n\\n \\\n",
    "    ==================================================\\n \\\n",
    "    ===== 5. Train SVD model by pandas_UDF ===========\\n \\\n",
    "    ==================================================\\n\\n\")\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"train_period\", IntegerType(), True),\n",
    "        StructField('start_test', DateType(),True),\n",
    "        StructField(\"n_factors\", IntegerType(), True),\n",
    "        StructField(\"n_epochs\", IntegerType(), True),\n",
    "        StructField('reg_all', FloatType(),True),\n",
    "        StructField('rmse', FloatType(),True),\n",
    "        StructField('map12', FloatType(),True),\n",
    "     ]\n",
    ")\n",
    "\n",
    "results = df.groupby('group_id').applyInPandas(time_split_cv.time_split_hyperparameter_search, schema)\n",
    "del df\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\n\\n \\\n",
    "    ==================================================\\n \\\n",
    "    ===== results.rdd.getNumPartitions() = {results.rdd.getNumPartitions()} ===========\\n \\\n",
    "    ==================================================\\n\\n\")\n",
    "\n",
    "\n",
    "print(f\"\\n\\n \\\n",
    "    ==================================================\\n \\\n",
    "    ===== 6. Save result table to parquet ============\\n \\\n",
    "    ==================================================\\n\\n\")\n",
    "results.coalesce(1).write.parquet(f'/user/HM_parquet/SVD_model/params/para{TRAIN_PERIOD}.parquet',mode='overwrite')\n",
    "\n",
    "print(f\"\\n\\n \\\n",
    "    ==================================================\\n \\\n",
    "    =====================  存檔完成 ===================\\n \\\n",
    "    ==================================================\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3316de-ae67-4202-83a7-ca38cf791e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 19:41:00,604 WARN scheduler.TaskSetManager: Lost task 21.0 in stage 162.0 (TID 17350) (bdse137.example.com executor 7): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000008/pyspark.zip/pyspark/worker.py\", line 603, in main\n",
      "    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000008/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n",
      "    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000008/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n",
      "    f, return_type = read_command(pickleSer, infile)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000008/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n",
      "    command = serializer._read_with_length(file)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000008/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n",
      "    return self.loads(obj)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000008/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n",
      "    return pickle.loads(obj, encoding=encoding)\n",
      "ModuleNotFoundError: No module named 'module'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "2022-04-10 19:41:03,001 WARN scheduler.TaskSetManager: Lost task 10.0 in stage 162.0 (TID 17349) (bdse106.example.com executor 2): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000003/pyspark.zip/pyspark/worker.py\", line 603, in main\n",
      "    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000003/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n",
      "    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000003/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n",
      "    f, return_type = read_command(pickleSer, infile)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000003/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n",
      "    command = serializer._read_with_length(file)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000003/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n",
      "    return self.loads(obj)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000003/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n",
      "    return pickle.loads(obj, encoding=encoding)\n",
      "ModuleNotFoundError: No module named 'module'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "2022-04-10 19:41:03,136 WARN scheduler.TaskSetManager: Lost task 6.0 in stage 162.0 (TID 17357) (bdse74.example.com executor 8): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000009/pyspark.zip/pyspark/worker.py\", line 603, in main\n",
      "    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000009/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n",
      "    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000009/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n",
      "    f, return_type = read_command(pickleSer, infile)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000009/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n",
      "    command = serializer._read_with_length(file)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000009/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n",
      "    return self.loads(obj)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000009/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n",
      "    return pickle.loads(obj, encoding=encoding)\n",
      "ModuleNotFoundError: No module named 'module'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "2022-04-10 19:41:03,145 WARN scheduler.TaskSetManager: Lost task 4.0 in stage 162.0 (TID 17347) (bdse75.example.com executor 5): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 603, in main\n",
      "    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n",
      "    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n",
      "    f, return_type = read_command(pickleSer, infile)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n",
      "    command = serializer._read_with_length(file)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n",
      "    return self.loads(obj)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n",
      "    return pickle.loads(obj, encoding=encoding)\n",
      "ModuleNotFoundError: No module named 'module'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "2022-04-10 19:41:09,817 ERROR scheduler.TaskSetManager: Task 4 in stage 162.0 failed 4 times; aborting job\n",
      "2022-04-10 19:41:09,823 ERROR datasources.FileFormatWriter: Aborting job 94c8f016-a721-4cba-9ffa-cffdf4be9884.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 162.0 failed 4 times, most recent failure: Lost task 4.3 in stage 162.0 (TID 17374) (bdse75.example.com executor 5): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 603, in main\n",
      "    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n",
      "    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n",
      "    f, return_type = read_command(pickleSer, infile)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n",
      "    command = serializer._read_with_length(file)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n",
      "    return self.loads(obj)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n",
      "    return pickle.loads(obj, encoding=encoding)\n",
      "ModuleNotFoundError: No module named 'module'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:218)\n",
      "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:110)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:110)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:106)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:106)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:93)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:91)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:128)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:781)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 603, in main\n",
      "    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n",
      "    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n",
      "    f, return_type = read_command(pickleSer, infile)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n",
      "    command = serializer._read_with_length(file)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n",
      "    return self.loads(obj)\n",
      "  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n",
      "    return pickle.loads(obj, encoding=encoding)\n",
      "ModuleNotFoundError: No module named 'module'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n",
      "\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "2022-04-10 19:41:09,862 WARN scheduler.TaskSetManager: Lost task 21.2 in stage 162.0 (TID 17373) (bdse137.example.com executor 7): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:09,920 WARN scheduler.TaskSetManager: Lost task 12.0 in stage 162.0 (TID 17375) (bdse74.example.com executor 8): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:09,994 WARN scheduler.TaskSetManager: Lost task 11.0 in stage 162.0 (TID 17362) (bdse75.example.com executor 5): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:09,995 WARN scheduler.TaskSetManager: Lost task 7.3 in stage 162.0 (TID 17376) (bdse75.example.com executor 5): TaskKilled (Stage cancelled)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o4925.parquet.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.jobAbortedError(QueryExecutionErrors.scala:496)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:251)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:110)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:110)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:106)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:106)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:93)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:91)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:128)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:781)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 162.0 failed 4 times, most recent failure: Lost task 4.3 in stage 162.0 (TID 17374) (bdse75.example.com executor 5): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 603, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n    command = serializer._read_with_length(file)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n    return self.loads(obj)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n    return pickle.loads(obj, encoding=encoding)\nModuleNotFoundError: No module named 'module'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:218)\n\t... 42 more\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 603, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n    command = serializer._read_with_length(file)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n    return self.loads(obj)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n    return pickle.loads(obj, encoding=encoding)\nModuleNotFoundError: No module named 'module'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# results.coalesce(1).write.parquet(f'/user/HM_parquet/SVD_model/params/para{TRAIN_PERIOD}.parquet',mode='overwrite')\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/user/HM_parquet/SVD_model/params/para\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mTRAIN_PERIOD\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:885\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m--> 885\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o4925.parquet.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.jobAbortedError(QueryExecutionErrors.scala:496)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:251)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:110)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:110)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:106)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:106)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:93)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:91)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:128)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:781)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 162.0 failed 4 times, most recent failure: Lost task 4.3 in stage 162.0 (TID 17374) (bdse75.example.com executor 5): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 603, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n    command = serializer._read_with_length(file)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n    return self.loads(obj)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n    return pickle.loads(obj, encoding=encoding)\nModuleNotFoundError: No module named 'module'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1160)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1160)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2642)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:218)\n\t... 42 more\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 603, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 423, in read_udfs\n    arg_offsets, f = read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=0)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n    command = serializer._read_with_length(file)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n    return self.loads(obj)\n  File \"/hdpfs/nm-local-dir/usercache/hadoop/appcache/application_1649580732736_0001/container_e51_1649580732736_0001_01_000006/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n    return pickle.loads(obj, encoding=encoding)\nModuleNotFoundError: No module named 'module'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:555)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:101)\n\tat org.apache.spark.sql.execution.python.PythonArrowOutput$$anon$1.read(PythonArrowOutput.scala:50)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:508)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:286)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 19:41:10,187 WARN scheduler.TaskSetManager: Lost task 26.0 in stage 162.0 (TID 17337) (bdse90.example.com executor 6): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:10,232 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 162.0 (TID 17343) (bdse92.example.com executor 1): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:10,232 WARN scheduler.TaskSetManager: Lost task 27.0 in stage 162.0 (TID 17354) (bdse92.example.com executor 1): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:10,269 WARN scheduler.TaskSetManager: Lost task 20.0 in stage 162.0 (TID 17355) (bdse93.example.com executor 4): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:10,270 WARN scheduler.TaskSetManager: Lost task 16.0 in stage 162.0 (TID 17344) (bdse93.example.com executor 4): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:10,315 WARN scheduler.TaskSetManager: Lost task 24.1 in stage 162.0 (TID 17372) (bdse106.example.com executor 2): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:10,317 WARN scheduler.TaskSetManager: Lost task 10.2 in stage 162.0 (TID 17370) (bdse106.example.com executor 2): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:10,538 WARN scheduler.TaskSetManager: Lost task 9.0 in stage 162.0 (TID 17342) (bdse109.example.com executor 9): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:10,540 WARN scheduler.TaskSetManager: Lost task 15.0 in stage 162.0 (TID 17353) (bdse109.example.com executor 9): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:10,693 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 162.0 (TID 17341) (bdse91.example.com executor 10): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:10,694 WARN scheduler.TaskSetManager: Lost task 29.0 in stage 162.0 (TID 17352) (bdse91.example.com executor 10): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:10,840 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 162.0 (TID 17340) (bdse108.example.com executor 3): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:10,841 WARN scheduler.TaskSetManager: Lost task 22.0 in stage 162.0 (TID 17351) (bdse108.example.com executor 3): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:11,549 WARN scheduler.TaskSetManager: Lost task 31.0 in stage 162.0 (TID 17359) (bdse137.example.com executor 7): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:21,169 WARN scheduler.TaskSetManager: Lost task 28.0 in stage 162.0 (TID 17348) (bdse90.example.com executor 6): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:26,600 WARN scheduler.TaskSetManager: Lost task 14.0 in stage 162.0 (TID 17345) (bdse89.example.com executor 11): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:26,600 WARN scheduler.TaskSetManager: Lost task 25.0 in stage 162.0 (TID 17356) (bdse89.example.com executor 11): TaskKilled (Stage cancelled)\n",
      "2022-04-10 19:41:33,012 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 162.0 (TID 17346) (bdse74.example.com executor 8): TaskKilled (Stage cancelled)\n"
     ]
    }
   ],
   "source": [
    "# results.coalesce(1).write.parquet(f'/user/HM_parquet/SVD_model/params/para{TRAIN_PERIOD}.parquet',mode='overwrite')\n",
    "results.write.parquet(f'/user/HM_parquet/SVD_model/params/para{TRAIN_PERIOD}.parquet',mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32fafb5-1a36-46ac-8003-f1cec9801d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46fb6755-2c57-42c6-b6ed-758d78f3d21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 16:13:04,316 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 28 for reason Container from a bad node: container_e50_1649562268781_0008_01_000001 on host: bdse93.example.com. Exit status: 143. Diagnostics: [2022-04-10 16:13:00.889]Container killed on request. Exit code is 143\n",
      "[2022-04-10 16:13:01.144]Container exited with a non-zero exit code 143. \n",
      "[2022-04-10 16:13:01.144]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:13:04,316 ERROR cluster.YarnScheduler: Lost executor 28 on bdse93.example.com: Container from a bad node: container_e50_1649562268781_0008_01_000001 on host: bdse93.example.com. Exit status: 143. Diagnostics: [2022-04-10 16:13:00.889]Container killed on request. Exit code is 143\n",
      "[2022-04-10 16:13:01.144]Container exited with a non-zero exit code 143. \n",
      "[2022-04-10 16:13:01.144]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:13:04,317 WARN scheduler.TaskSetManager: Lost task 8.0 in stage 344.0 (TID 40163) (bdse93.example.com executor 28): ExecutorLostFailure (executor 28 exited caused by one of the running tasks) Reason: Container from a bad node: container_e50_1649562268781_0008_01_000001 on host: bdse93.example.com. Exit status: 143. Diagnostics: [2022-04-10 16:13:00.889]Container killed on request. Exit code is 143\n",
      "[2022-04-10 16:13:01.144]Container exited with a non-zero exit code 143. \n",
      "[2022-04-10 16:13:01.144]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:13:04,317 WARN scheduler.TaskSetManager: Lost task 16.0 in stage 344.0 (TID 40171) (bdse93.example.com executor 28): ExecutorLostFailure (executor 28 exited caused by one of the running tasks) Reason: Container from a bad node: container_e50_1649562268781_0008_01_000001 on host: bdse93.example.com. Exit status: 143. Diagnostics: [2022-04-10 16:13:00.889]Container killed on request. Exit code is 143\n",
      "[2022-04-10 16:13:01.144]Container exited with a non-zero exit code 143. \n",
      "[2022-04-10 16:13:01.144]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:16:51,170 WARN scheduler.TaskSetManager: Lost task 8.1 in stage 344.0 (TID 40176) (bdse93.example.com executor 29): FetchFailed(null, shuffleId=93, mapIndex=-1, mapId=-1, reduceId=344, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 93 partition 344\n",
      "\tat org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1619)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1566)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1565)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1565)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1230)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1192)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "2022-04-10 16:16:51,171 WARN scheduler.TaskSetManager: Lost task 16.1 in stage 344.0 (TID 40175) (bdse93.example.com executor 29): FetchFailed(null, shuffleId=93, mapIndex=-1, mapId=-1, reduceId=670, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 93 partition 670\n",
      "\tat org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1619)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1566)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1565)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1565)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1230)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1192)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "2022-04-10 16:26:46,177 ERROR cluster.YarnScheduler: Lost executor 23 on bdse42.example.com: Container from a bad node: container_e48_1649562268781_0008_01_000003 on host: bdse42.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:26:36.662]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:26:37.900]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:26:38.204]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:26:46,178 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 349.0 (TID 40397) (bdse42.example.com executor 23): ExecutorLostFailure (executor 23 exited caused by one of the running tasks) Reason: Container from a bad node: container_e48_1649562268781_0008_01_000003 on host: bdse42.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:26:36.662]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:26:37.900]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:26:38.204]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:26:46,178 WARN scheduler.TaskSetManager: Lost task 6.0 in stage 349.0 (TID 40406) (bdse42.example.com executor 23): ExecutorLostFailure (executor 23 exited caused by one of the running tasks) Reason: Container from a bad node: container_e48_1649562268781_0008_01_000003 on host: bdse42.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:26:36.662]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:26:37.900]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:26:38.204]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:26:46,177 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 23 for reason Container from a bad node: container_e48_1649562268781_0008_01_000003 on host: bdse42.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:26:36.662]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:26:37.900]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:26:38.204]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:27:15,768 WARN scheduler.TaskSetManager: Lost task 6.1 in stage 349.0 (TID 40415) (bdse42.example.com executor 30): FetchFailed(null, shuffleId=97, mapIndex=-1, mapId=-1, reduceId=10, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 97 partition 10\n",
      "\tat org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1619)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1566)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1565)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1565)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1230)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1192)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "2022-04-10 16:27:15,772 WARN scheduler.TaskSetManager: Lost task 0.1 in stage 349.0 (TID 40416) (bdse42.example.com executor 30): FetchFailed(null, shuffleId=97, mapIndex=-1, mapId=-1, reduceId=0, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 97 partition 0\n",
      "\tat org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1619)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1566)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1565)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1565)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1230)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1192)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "2022-04-10 16:27:15,795 WARN scheduler.TaskSetManager: Lost task 10.0 in stage 349.0 (TID 40417) (bdse42.example.com executor 30): FetchFailed(null, shuffleId=97, mapIndex=-1, mapId=-1, reduceId=16, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 97 partition 16\n",
      "\tat org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1619)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1566)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1565)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1565)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1230)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1192)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "2022-04-10 16:27:54,885 ERROR cluster.YarnScheduler: Lost executor 26 on bdse74.example.com: Container from a bad node: container_e49_1649562268781_0008_01_000002 on host: bdse74.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:27:49.148]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:27:50.614]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:27:50.636]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:27:54,889 WARN scheduler.TaskSetManager: Lost task 16.0 in stage 349.0 (TID 40413) (bdse74.example.com executor 26): ExecutorLostFailure (executor 26 exited caused by one of the running tasks) Reason: Container from a bad node: container_e49_1649562268781_0008_01_000002 on host: bdse74.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:27:49.148]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:27:50.614]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:27:50.636]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:27:54,889 WARN scheduler.TaskSetManager: Lost task 12.0 in stage 349.0 (TID 40404) (bdse74.example.com executor 26): ExecutorLostFailure (executor 26 exited caused by one of the running tasks) Reason: Container from a bad node: container_e49_1649562268781_0008_01_000002 on host: bdse74.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:27:49.148]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:27:50.614]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:27:50.636]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:27:54,890 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 26 for reason Container from a bad node: container_e49_1649562268781_0008_01_000002 on host: bdse74.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:27:49.148]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:27:50.614]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:27:50.636]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_12 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_373 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_23 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_56 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_315 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_107 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_333 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_79 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_252 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_351 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_95 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_31 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_418 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_429 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_233 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_63 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_431 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_143 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_27 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_117 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_227 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_391 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_142 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_240 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_448 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_299 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_311 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_165 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_145 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_289 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_229 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_458 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_362 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_146 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_241 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_392 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_292 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_291 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_69 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_110 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_371 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_256 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_153 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_287 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_354 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_356 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_30 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_12 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_13 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_154 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_302 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_416 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_155 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_153 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_169 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_19 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_77 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_123 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_380 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_306 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_225 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_367 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_441 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_381 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_5 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_121 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_83 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_79 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_227 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_218 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_159 !\n",
      "2022-04-10 16:28:52,570 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_113 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_69 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_243 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_182 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_245 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_157 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_60 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_409 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_28 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_354 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_176 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_185 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_24 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_105 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_108 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_174 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_319 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_70 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_334 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_261 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_381 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_359 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_132 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_260 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_193 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_327 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_141 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_307 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_302 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_90 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_181 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_57 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_246 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_100 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_24 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_222 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_257 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_124 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_230 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_48 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_87 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_85 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_312 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_163 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_310 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_219 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_156 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_55 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_455 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_134 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_288 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_397 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_128 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_18 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_216 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_202 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_71 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_298 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_323 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_168 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_394 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_352 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_355 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_37 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_135 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_280 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_281 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_436 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_316 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_203 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_262 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_348 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_272 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_199 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_413 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_93 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_317 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_359 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_295 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_383 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_401 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_161 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_59 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_231 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_243 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_320 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_40 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_337 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_419 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_281 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_382 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_422 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_135 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_267 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_301 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_422 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_149 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_327 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_430 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_358 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_158 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_385 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_212 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_32 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_25 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_309 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_452 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_247 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_390 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_439 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_111 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_459 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_137 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_226 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_313 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_326 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_100 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_320 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_296 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_67 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_454 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_406 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_89 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_380 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_417 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_139 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_458 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_208 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_80 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_166 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_38 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_308 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_379 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_8 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_261 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_146 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_91 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_13 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_112 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_262 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_233 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_336 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_189 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_377 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_113 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_110 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_46 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_411 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_271 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_75 !\n",
      "2022-04-10 16:28:52,571 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_119 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_177 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_292 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_335 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_190 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_297 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_87 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_194 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_407 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_427 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_267 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_295 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_342 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_88 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_15 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_116 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_376 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_385 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_65 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_175 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_363 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_64 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_42 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_270 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_237 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_119 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_208 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_265 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_159 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_338 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_86 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_395 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_300 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_104 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_269 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_136 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_178 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_451 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_232 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_257 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_326 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_47 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_407 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_256 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_53 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_206 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_388 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_73 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_131 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_285 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_438 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_408 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_52 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_150 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_106 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_283 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_344 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_349 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_44 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_403 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_30 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_455 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_258 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_450 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_324 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_179 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_453 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_286 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_183 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_207 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_74 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_331 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_446 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_61 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_340 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_403 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_445 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_52 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_200 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_410 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_329 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_372 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_374 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_290 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_22 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_284 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_180 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_31 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_386 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_193 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_457 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_25 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_420 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_440 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_277 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_287 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_118 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_425 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_184 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_147 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_39 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_108 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_452 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_249 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_242 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_212 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_274 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_268 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_346 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_72 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_73 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_171 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_205 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_226 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_49 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_288 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_188 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_152 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_411 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_390 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_201 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_438 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_276 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_428 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_18 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_249 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_322 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_96 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_59 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_26 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_76 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_221 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_404 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_120 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_210 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_6 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_330 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_148 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_338 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_223 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_9 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_304 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_200 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_94 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_14 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_389 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_301 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_21 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_443 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_216 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_109 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_314 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_129 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_195 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_85 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_29 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_271 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_357 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_286 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_400 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_424 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_392 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_328 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_60 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_220 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_437 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_234 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_360 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_441 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_17 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_62 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_11 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_346 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_166 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_405 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_164 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_275 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_447 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_17 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_297 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_198 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_127 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_191 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_313 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_386 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_217 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_82 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_40 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_318 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_215 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_101 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_170 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_449 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_180 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_344 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_58 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_204 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_0 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_238 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_266 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_192 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_282 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_151 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_93 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_78 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_197 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_279 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_239 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_10 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_323 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_143 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_7 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_130 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_335 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_306 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_48 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_160 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_376 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_294 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_430 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_368 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_432 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_68 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_414 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_65 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_274 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_34 !\n",
      "2022-04-10 16:28:52,573 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_236 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_140 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_186 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_412 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_369 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_66 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_36 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_416 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_55 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_341 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_91 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_98 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_167 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_396 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_235 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_92 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_426 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_384 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_219 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_176 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_172 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_88 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_456 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_255 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_185 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_340 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_171 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_173 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_133 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_118 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_162 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_293 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_83 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_437 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_128 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_198 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_445 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_434 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_43 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_50 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_97 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_248 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_240 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_224 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_433 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_364 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_16 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_444 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_138 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_191 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_33 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_213 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_204 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_75 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_440 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_5 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_366 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_35 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_139 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_187 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_347 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_259 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_399 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_435 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_423 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_387 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_125 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_395 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_311 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_103 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_244 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_303 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_304 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_151 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_353 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_45 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_250 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_413 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_131 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_196 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_273 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_280 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_339 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_402 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_106 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_375 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_329 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_115 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_414 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_172 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_350 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_278 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_84 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_305 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_370 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_41 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_163 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_404 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_345 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_37 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_362 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_122 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_442 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_234 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_247 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_102 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_353 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_418 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_448 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_220 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_276 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_209 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_421 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_214 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_144 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_398 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_433 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_332 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_361 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_47 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_20 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_333 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_103 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_114 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_239 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_211 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_365 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_408 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_51 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_81 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_343 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_228 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_366 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_251 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_126 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_425 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_321 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_378 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_254 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_99 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_54 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_374 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_393 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_136 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_253 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_415 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_325 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_322 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_264 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1121_2 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_263 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_396 !\n",
      "2022-04-10 16:28:52,574 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_1524_3 !\n",
      "2022-04-10 16:29:31,616 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 19 for reason Container from a bad node: container_e46_1649562268781_0008_01_000020 on host: bdse89.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:29:10.095]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:29:15.149]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:29:15.779]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:29:31,616 ERROR cluster.YarnScheduler: Lost executor 19 on bdse89.example.com: Container from a bad node: container_e46_1649562268781_0008_01_000020 on host: bdse89.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:29:10.095]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:29:15.149]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:29:15.779]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:29:31,617 WARN scheduler.TaskSetManager: Lost task 28.0 in stage 349.0 (TID 40412) (bdse89.example.com executor 19): ExecutorLostFailure (executor 19 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000020 on host: bdse89.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:29:10.095]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:29:15.149]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:29:15.779]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:29:31,617 WARN scheduler.TaskSetManager: Lost task 26.0 in stage 349.0 (TID 40403) (bdse89.example.com executor 19): ExecutorLostFailure (executor 19 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000020 on host: bdse89.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:29:10.095]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:29:15.149]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:29:15.779]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:30:52,438 ERROR cluster.YarnScheduler: Lost executor 24 on bdse91.example.com: Container from a bad node: container_e48_1649562268781_0008_01_000004 on host: bdse91.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:30:24.944]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:30:32.578]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:30:34.155]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:30:52,439 WARN scheduler.TaskSetManager: Lost task 15.0 in stage 349.0 (TID 40414) (bdse91.example.com executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Container from a bad node: container_e48_1649562268781_0008_01_000004 on host: bdse91.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:30:24.944]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:30:32.578]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:30:34.155]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:30:52,439 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 349.0 (TID 40405) (bdse91.example.com executor 24): ExecutorLostFailure (executor 24 exited caused by one of the running tasks) Reason: Container from a bad node: container_e48_1649562268781_0008_01_000004 on host: bdse91.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:30:24.944]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:30:32.578]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:30:34.155]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:30:52,439 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 24 for reason Container from a bad node: container_e48_1649562268781_0008_01_000004 on host: bdse91.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:30:24.944]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:30:32.578]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:30:34.155]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:31:55,047 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 18 for reason Container from a bad node: container_e46_1649562268781_0008_01_000019 on host: bdse90.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:31:31.126]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:31:36.755]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:31:38.380]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:31:55,047 ERROR cluster.YarnScheduler: Lost executor 18 on bdse90.example.com: Container from a bad node: container_e46_1649562268781_0008_01_000019 on host: bdse90.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:31:31.126]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:31:36.755]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:31:38.380]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:31:55,048 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 349.0 (TID 40400) (bdse90.example.com executor 18): ExecutorLostFailure (executor 18 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000019 on host: bdse90.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:31:31.126]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:31:36.755]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:31:38.380]Killed by external signal\n",
      ".\n",
      "2022-04-10 16:31:55,048 WARN scheduler.TaskSetManager: Lost task 27.0 in stage 349.0 (TID 40409) (bdse90.example.com executor 18): ExecutorLostFailure (executor 18 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000019 on host: bdse90.example.com. Exit status: 137. Diagnostics: [2022-04-10 16:31:31.126]Container killed on request. Exit code is 137\n",
      "[2022-04-10 16:31:36.755]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 16:31:38.380]Killed by external signal\n",
      ".\n",
      "ERROR:root:KeyboardInterrupt while sending command.][Stage 346:(270 + 1) / 271]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py\", line 475, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:680\u001b[0m, in \u001b[0;36mDataFrame.count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    671\u001b[0m     \u001b[38;5;124;03m\"\"\"Returns the number of rows in this :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m    672\u001b[0m \n\u001b[1;32m    673\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;124;03m    2\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 680\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/clientserver.py:475\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    476\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f3fe5d-6ade-40ca-96d5-14ceabd91967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = timeit('main()', setup='gc.enable(); TRAIN_PERIOD = 60', number=1)\n",
    "# print(f\"\\n\\n \\\n",
    "# ==================================================\\n \\\n",
    "# ================== 執行時長: {t} ==================\\n \\\n",
    "# ==================================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78d2ef5a-b507-4275-b74e-71135df6b3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 105:==================================================>(2023 + 1) / 2024]77]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "         ==================================================\n",
      "         ===== df.rdd.getNumPartitions() = 23 ===========\n",
      "         ==================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "         ==================================================\n",
      "         ===== 5. Train SVD model by pandas_UDF ===========\n",
      "         ==================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 126:====================================================>  (22 + 1) / 23]7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "         ==================================================\n",
      "         ===== results.rdd.getNumPartitions() = 178 ===========\n",
      "         ==================================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "         ==================================================\n",
      "         ===== 6. Save result table to parquet ============\n",
      "         ==================================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 12:40:14,368 ERROR cluster.YarnScheduler: Lost executor 6 on bdse92.example.com: Container from a bad node: container_e46_1649562268781_0008_01_000007 on host: bdse92.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:39:45.039]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:39:54.597]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:39:55.231]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:40:14,368 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 6 for reason Container from a bad node: container_e46_1649562268781_0008_01_000007 on host: bdse92.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:39:45.039]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:39:54.597]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:39:55.231]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:40:14,372 WARN scheduler.TaskSetManager: Lost task 4.0 in stage 144.0 (TID 14290) (bdse92.example.com executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000007 on host: bdse92.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:39:45.039]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:39:54.597]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:39:55.231]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:40:14,374 WARN scheduler.TaskSetManager: Lost task 20.0 in stage 144.0 (TID 14301) (bdse92.example.com executor 6): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000007 on host: bdse92.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:39:45.039]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:39:54.597]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:39:55.231]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:40:57,390 WARN scheduler.TaskSetManager: Lost task 4.1 in stage 144.0 (TID 14313) (bdse74.example.com executor 4): FetchFailed(BlockManagerId(6, bdse92.example.com, 40499, None), shuffleId=40, mapIndex=21, mapId=14285, reduceId=4, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat scala.collection.Iterator.isEmpty(Iterator.scala:387)\n",
      "\tat scala.collection.Iterator.isEmpty$(Iterator.scala:387)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.isEmpty(WholeStageCodegenExec.scala:757)\n",
      "\tat org.apache.spark.sql.execution.python.FlatMapGroupsInPandasExec.$anonfun$doExecute$1(FlatMapGroupsInPandasExec.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 6), which maintains the block data to fetch is dead.\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:136)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.start(RetryingBlockTransferor.java:133)\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:146)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:362)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.send$1(ShuffleBlockFetcherIterator.scala:1135)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:1127)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:1000)\n",
      "\t... 29 more\n",
      "\n",
      ")\n",
      "2022-04-10 12:42:21,561 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 7 for reason Container from a bad node: container_e46_1649562268781_0008_01_000008 on host: bdse109.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:41:14.747]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:41:26.397]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:41:35.757]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:42:21,562 ERROR cluster.YarnScheduler: Lost executor 7 on bdse109.example.com: Container from a bad node: container_e46_1649562268781_0008_01_000008 on host: bdse109.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:41:14.747]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:41:26.397]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:41:35.757]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:42:21,563 WARN scheduler.TaskSetManager: Lost task 6.0 in stage 144.0 (TID 14300) (bdse109.example.com executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000008 on host: bdse109.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:41:14.747]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:41:26.397]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:41:35.757]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:42:21,563 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 144.0 (TID 14289) (bdse109.example.com executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000008 on host: bdse109.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:41:14.747]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:41:26.397]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:41:35.757]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:42:44,068 WARN scheduler.TaskSetManager: Lost task 20.1 in stage 144.0 (TID 14312) (bdse90.example.com executor 2): FetchFailed(BlockManagerId(11, bdse108.example.com, 43065, None), shuffleId=40, mapIndex=10, mapId=14274, reduceId=23, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat scala.collection.Iterator.isEmpty(Iterator.scala:387)\n",
      "\tat scala.collection.Iterator.isEmpty$(Iterator.scala:387)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.isEmpty(WholeStageCodegenExec.scala:757)\n",
      "\tat org.apache.spark.sql.execution.python.FlatMapGroupsInPandasExec.$anonfun$doExecute$1(FlatMapGroupsInPandasExec.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 11), which maintains the block data to fetch is dead.\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:136)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "2022-04-10 12:42:45,597 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 11 for reason Container from a bad node: container_e46_1649562268781_0008_01_000012 on host: bdse108.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:42:12.209]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:42:26.525]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:42:28.587]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:42:45,598 ERROR cluster.YarnScheduler: Lost executor 11 on bdse108.example.com: Container from a bad node: container_e46_1649562268781_0008_01_000012 on host: bdse108.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:42:12.209]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:42:26.525]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:42:28.587]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:42:45,598 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 144.0 (TID 14287) (bdse108.example.com executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000012 on host: bdse108.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:42:12.209]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:42:26.525]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:42:28.587]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:42:45,598 WARN scheduler.TaskSetManager: Lost task 9.0 in stage 144.0 (TID 14298) (bdse108.example.com executor 11): ExecutorLostFailure (executor 11 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000012 on host: bdse108.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:42:12.209]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:42:26.525]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:42:28.587]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:42:58,061 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 10 for reason Container from a bad node: container_e46_1649562268781_0008_01_000011 on host: bdse42.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:42:56.067]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:42:56.230]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:42:56.357]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:42:58,061 ERROR cluster.YarnScheduler: Lost executor 10 on bdse42.example.com: Container from a bad node: container_e46_1649562268781_0008_01_000011 on host: bdse42.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:42:56.067]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:42:56.230]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:42:56.357]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:42:58,062 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 144.0 (TID 14291) (bdse42.example.com executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000011 on host: bdse42.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:42:56.067]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:42:56.230]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:42:56.357]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:42:58,062 WARN scheduler.TaskSetManager: Lost task 15.0 in stage 144.0 (TID 14311) (bdse42.example.com executor 10): ExecutorLostFailure (executor 10 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000011 on host: bdse42.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:42:56.067]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:42:56.230]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:42:56.357]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:43:15,443 ERROR cluster.YarnScheduler: Lost executor 4 on bdse74.example.com: Container from a bad node: container_e46_1649562268781_0008_01_000005 on host: bdse74.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:43:09.626]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:43:11.863]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:43:12.046]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:43:15,443 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 4 for reason Container from a bad node: container_e46_1649562268781_0008_01_000005 on host: bdse74.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:43:09.626]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:43:11.863]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:43:12.046]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:43:15,444 WARN scheduler.TaskSetManager: Lost task 24.0 in stage 144.0 (TID 14314) (bdse74.example.com executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000005 on host: bdse74.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:43:09.626]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:43:11.863]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:43:12.046]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:43:15,444 WARN scheduler.TaskSetManager: Lost task 18.0 in stage 144.0 (TID 14310) (bdse74.example.com executor 4): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000005 on host: bdse74.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:43:09.626]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:43:11.863]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:43:12.046]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:53:35,837 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_220 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_443 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_43 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_354 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_46 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_129 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_279 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_376 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_312 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_91 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_11 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_412 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_162 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_67 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_205 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_245 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_171 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_345 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_322 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_240 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_264 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_303 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_144 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_192 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_307 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_109 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_103 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_298 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_378 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_120 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_450 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_11 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_364 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_215 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_127 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_140 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_234 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_14 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_16 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_139 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_158 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_274 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_427 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_311 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_107 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_405 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_68 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_423 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_161 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_1 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_0 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_211 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_393 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_328 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_433 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_115 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_120 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_230 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_89 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_162 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_4 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_65 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_94 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_196 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_146 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_371 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_304 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_292 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_100 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_55 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_303 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_63 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_40 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_459 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_29 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_95 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_25 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_49 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_336 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_221 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_24 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_341 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_235 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_453 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_411 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_323 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_375 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_427 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_37 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_451 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_60 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_83 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_57 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_25 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_326 !\n",
      "2022-04-10 12:53:35,838 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_29 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_125 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_90 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_226 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_391 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_131 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_402 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_154 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_68 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_362 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_64 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_70 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_142 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_12 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_369 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_15 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_77 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_176 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_284 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_321 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_451 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_210 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_282 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_149 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_179 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_123 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_200 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_333 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_428 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_434 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_74 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_114 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_426 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_224 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_128 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_364 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_215 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_289 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_99 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_67 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_401 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_252 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_53 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_21 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_357 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_227 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_190 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_190 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_253 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_315 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_57 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_9 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_254 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_277 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_353 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_62 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_186 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_297 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_259 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_195 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_339 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_246 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_372 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_135 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_435 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_72 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_298 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_335 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_73 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_229 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_32 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_81 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_416 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_408 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_214 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_23 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_223 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_422 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_351 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_37 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_111 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_273 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_442 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_394 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_445 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_108 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_148 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_166 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_439 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_417 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_84 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_340 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_18 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_19 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_214 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_96 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_444 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_346 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_450 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_44 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_31 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_44 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_107 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_33 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_366 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_267 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_125 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_300 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_432 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_379 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_184 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_391 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_325 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_100 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_382 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_295 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_383 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_138 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_80 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_337 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_277 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_91 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_402 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_38 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_126 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_52 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_242 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_250 !\n",
      "2022-04-10 12:53:35,839 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_130 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_407 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_176 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_188 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_454 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_345 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_314 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_286 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_458 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_157 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_203 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_436 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_272 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_233 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_233 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_267 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_269 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_115 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_121 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_361 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_116 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_393 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_387 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_3 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_262 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_177 !\n",
      "2022-04-10 12:53:35,840 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_202 !\n",
      "2022-04-10 12:53:44,879 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 3 for reason Container from a bad node: container_e46_1649562268781_0008_01_000004 on host: bdse89.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:53:38.149]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:53:39.861]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:53:39.922]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:53:44,879 ERROR cluster.YarnScheduler: Lost executor 3 on bdse89.example.com: Container from a bad node: container_e46_1649562268781_0008_01_000004 on host: bdse89.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:53:38.149]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:53:39.861]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:53:39.922]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:53:44,880 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 144.0 (TID 14288) (bdse89.example.com executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000004 on host: bdse89.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:53:38.149]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:53:39.861]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:53:39.922]Killed by external signal\n",
      ".\n",
      "2022-04-10 12:53:44,880 WARN scheduler.TaskSetManager: Lost task 7.0 in stage 144.0 (TID 14299) (bdse89.example.com executor 3): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000004 on host: bdse89.example.com. Exit status: 137. Diagnostics: [2022-04-10 12:53:38.149]Container killed on request. Exit code is 137\n",
      "[2022-04-10 12:53:39.861]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 12:53:39.922]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:01:10,264 WARN scheduler.TaskSetManager: Lost task 27.0 in stage 144.1 (TID 15128) (bdse42.example.com executor 15): FetchFailed(BlockManagerId(2, bdse90.example.com, 33335, None), shuffleId=40, mapIndex=19, mapId=14283, reduceId=47, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat scala.collection.Iterator.isEmpty(Iterator.scala:387)\n",
      "\tat scala.collection.Iterator.isEmpty$(Iterator.scala:387)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.isEmpty(WholeStageCodegenExec.scala:757)\n",
      "\tat org.apache.spark.sql.execution.python.FlatMapGroupsInPandasExec.$anonfun$doExecute$1(FlatMapGroupsInPandasExec.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 2), which maintains the block data to fetch is dead.\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:136)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "2022-04-10 13:01:17,249 ERROR cluster.YarnScheduler: Lost executor 2 on bdse90.example.com: Container from a bad node: container_e46_1649562268781_0008_01_000003 on host: bdse90.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:01:10.915]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:01:12.209]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:01:12.517]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:01:17,250 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 2 for reason Container from a bad node: container_e46_1649562268781_0008_01_000003 on host: bdse90.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:01:10.915]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:01:12.209]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:01:12.517]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:01:17,250 WARN scheduler.TaskSetManager: Lost task 21.0 in stage 144.1 (TID 15127) (bdse90.example.com executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000003 on host: bdse90.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:01:10.915]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:01:12.209]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:01:12.517]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:01:17,250 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 144.1 (TID 15117) (bdse90.example.com executor 2): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000003 on host: bdse90.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:01:10.915]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:01:12.209]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:01:12.517]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:04:49,160 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 143.3 (TID 15423) (bdse108.example.com executor 14): FetchFailed(null, shuffleId=36, mapIndex=-1, mapId=-1, reduceId=164, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 36 partition 164\n",
      "\tat org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1619)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1566)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1565)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1565)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1230)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1192)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:89)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "2022-04-10 13:04:49,566 ERROR cluster.YarnScheduler: Lost executor 17 on bdse89.example.com: Container from a bad node: container_e46_1649562268781_0008_01_000018 on host: bdse89.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:04:46.667]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:04:46.675]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:04:46.679]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:04:49,567 WARN scheduler.TaskSetManager: Lost task 30.0 in stage 144.1 (TID 15134) (bdse89.example.com executor 17): ExecutorLostFailure (executor 17 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000018 on host: bdse89.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:04:46.667]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:04:46.675]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:04:46.679]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:04:49,567 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 17 for reason Container from a bad node: container_e46_1649562268781_0008_01_000018 on host: bdse89.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:04:46.667]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:04:46.675]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:04:46.679]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:04:49,568 WARN scheduler.TaskSetManager: Lost task 28.0 in stage 144.1 (TID 15133) (bdse89.example.com executor 17): ExecutorLostFailure (executor 17 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000018 on host: bdse89.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:04:46.667]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:04:46.675]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:04:46.679]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:05:57,387 WARN scheduler.TaskSetManager: Lost task 12.0 in stage 144.1 (TID 15126) (bdse91.example.com executor 8): FetchFailed(BlockManagerId(2, bdse90.example.com, 33335, None), shuffleId=40, mapIndex=19, mapId=14283, reduceId=23, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat scala.collection.Iterator.isEmpty(Iterator.scala:387)\n",
      "\tat scala.collection.Iterator.isEmpty$(Iterator.scala:387)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.isEmpty(WholeStageCodegenExec.scala:757)\n",
      "\tat org.apache.spark.sql.execution.python.FlatMapGroupsInPandasExec.$anonfun$doExecute$1(FlatMapGroupsInPandasExec.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 2), which maintains the block data to fetch is dead.\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:136)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.start(RetryingBlockTransferor.java:133)\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:146)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:362)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.send$1(ShuffleBlockFetcherIterator.scala:1135)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:1127)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:1000)\n",
      "\t... 29 more\n",
      "\n",
      ")\n",
      "2022-04-10 13:11:14,777 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_13 !\n",
      "2022-04-10 13:11:14,778 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_14 !\n",
      "2022-04-10 13:11:14,778 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_45 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_295 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_144 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_60 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_93 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_112 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_119 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_404 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_134 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_194 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_358 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_375 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_392 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_291 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_342 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_441 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_395 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_61 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_212 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_240 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_381 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_82 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_367 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_181 !\n",
      "2022-04-10 13:11:14,779 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_420 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_5 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_260 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_196 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_258 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_47 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_385 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_96 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_373 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_71 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_380 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_324 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_198 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_266 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_338 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_136 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_28 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_163 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_355 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_128 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_234 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_42 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_8 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_418 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_449 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_187 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_297 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_111 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_185 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_203 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_126 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_139 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_27 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_321 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_65 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_117 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_48 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_171 !\n",
      "2022-04-10 13:11:14,780 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_155 !\n",
      "2022-04-10 13:11:14,781 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_23 !\n",
      "2022-04-10 13:11:14,781 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_104 !\n",
      "2022-04-10 13:11:14,781 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_24 !\n",
      "2022-04-10 13:11:14,781 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_331 !\n",
      "2022-04-10 13:11:14,781 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_333 !\n",
      "2022-04-10 13:11:14,783 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_354 !\n",
      "2022-04-10 13:11:14,783 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_85 !\n",
      "2022-04-10 13:11:14,783 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_213 !\n",
      "2022-04-10 13:11:14,783 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_281 !\n",
      "2022-04-10 13:11:14,783 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_421 !\n",
      "2022-04-10 13:11:14,783 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_263 !\n",
      "2022-04-10 13:11:14,783 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_382 !\n",
      "2022-04-10 13:11:14,783 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_110 !\n",
      "2022-04-10 13:11:14,783 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_341 !\n",
      "2022-04-10 13:11:14,783 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_79 !\n",
      "2022-04-10 13:11:14,783 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_284 !\n",
      "2022-04-10 13:11:14,783 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_5 !\n",
      "2022-04-10 13:11:14,783 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_218 !\n",
      "2022-04-10 13:11:14,783 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_160 !\n",
      "2022-04-10 13:11:14,784 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_59 !\n",
      "2022-04-10 13:11:14,784 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_336 !\n",
      "2022-04-10 13:11:14,784 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_268 !\n",
      "2022-04-10 13:11:14,784 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_118 !\n",
      "2022-04-10 13:11:14,785 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_296 !\n",
      "2022-04-10 13:11:14,785 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_399 !\n",
      "2022-04-10 13:11:14,785 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_458 !\n",
      "2022-04-10 13:11:14,785 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_192 !\n",
      "2022-04-10 13:11:14,785 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_259 !\n",
      "2022-04-10 13:11:14,785 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_145 !\n",
      "2022-04-10 13:11:14,785 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_226 !\n",
      "2022-04-10 13:11:14,785 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_207 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_250 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_368 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_406 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_88 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_447 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_76 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_396 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_323 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_360 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_301 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_330 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_380 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_47 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_425 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_159 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_248 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_392 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_455 !\n",
      "2022-04-10 13:11:14,787 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_88 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_244 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_249 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_169 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_219 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_224 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_143 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_216 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_430 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_121 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_156 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_403 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_232 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_434 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_413 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_397 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_182 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_361 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_288 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_166 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_103 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_424 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_342 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_337 !\n",
      "2022-04-10 13:11:14,788 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_232 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_229 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_398 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_208 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_318 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_454 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_426 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_302 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_254 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_204 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_326 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_219 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_41 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_129 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_33 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_66 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_269 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_113 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_448 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_151 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_127 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_271 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_420 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_43 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_255 !\n",
      "2022-04-10 13:11:14,789 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_173 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_36 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_245 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_194 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_276 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_280 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_165 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_66 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_137 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_146 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_316 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_251 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_58 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_51 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_20 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_306 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_174 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_365 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_137 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_238 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_301 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_152 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_189 !\n",
      "2022-04-10 13:11:14,790 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_350 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_363 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_431 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_18 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_366 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_189 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_81 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_425 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_330 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_178 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_199 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_106 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_317 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_261 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_2 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_191 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_216 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_184 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_363 !\n",
      "2022-04-10 13:11:14,791 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_309 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_275 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_204 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_310 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_35 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_92 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_9 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_165 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_440 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_93 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_53 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_416 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_435 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_279 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_299 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_143 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_101 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_448 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_238 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_180 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_237 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_419 !\n",
      "2022-04-10 13:11:14,792 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_104 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_51 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_72 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_157 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_241 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_222 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_69 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_133 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_86 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_201 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_175 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_174 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_32 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_371 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_286 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_378 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_2 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_155 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_310 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_69 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_350 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_305 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_390 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_211 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_599_243 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_54 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_22 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_414 !\n",
      "2022-04-10 13:11:14,793 WARN storage.BlockManagerMasterEndpoint: No more replicas available for rdd_497_388 !\n",
      "2022-04-10 13:11:19,787 WARN scheduler.TaskSetManager: Lost task 4.0 in stage 144.2 (TID 15439) (bdse42.example.com executor 15): FetchFailed(BlockManagerId(5, bdse75.example.com, 34469, None), shuffleId=40, mapIndex=16, mapId=15061, reduceId=10, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat scala.collection.Iterator.isEmpty(Iterator.scala:387)\n",
      "\tat scala.collection.Iterator.isEmpty$(Iterator.scala:387)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.isEmpty(WholeStageCodegenExec.scala:757)\n",
      "\tat org.apache.spark.sql.execution.python.FlatMapGroupsInPandasExec.$anonfun$doExecute$1(FlatMapGroupsInPandasExec.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 5), which maintains the block data to fetch is dead.\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:136)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "2022-04-10 13:11:19,814 WARN scheduler.TaskSetManager: Lost task 16.0 in stage 144.2 (TID 15438) (bdse89.example.com executor 19): FetchFailed(BlockManagerId(5, bdse75.example.com, 34469, None), shuffleId=40, mapIndex=8, mapId=14272, reduceId=42, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat scala.collection.Iterator.isEmpty(Iterator.scala:387)\n",
      "\tat scala.collection.Iterator.isEmpty$(Iterator.scala:387)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.isEmpty(WholeStageCodegenExec.scala:757)\n",
      "\tat org.apache.spark.sql.execution.python.FlatMapGroupsInPandasExec.$anonfun$doExecute$1(FlatMapGroupsInPandasExec.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 5), which maintains the block data to fetch is dead.\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:136)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "2022-04-10 13:11:19,837 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 144.2 (TID 15427) (bdse74.example.com executor 16): FetchFailed(BlockManagerId(5, bdse75.example.com, 34469, None), shuffleId=40, mapIndex=14, mapId=15113, reduceId=8, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat scala.collection.Iterator.isEmpty(Iterator.scala:387)\n",
      "\tat scala.collection.Iterator.isEmpty$(Iterator.scala:387)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.isEmpty(WholeStageCodegenExec.scala:757)\n",
      "\tat org.apache.spark.sql.execution.python.FlatMapGroupsInPandasExec.$anonfun$doExecute$1(FlatMapGroupsInPandasExec.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 5), which maintains the block data to fetch is dead.\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:136)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "2022-04-10 13:11:21,100 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 144.2 (TID 15433) (bdse106.example.com executor 1): FetchFailed(BlockManagerId(5, bdse75.example.com, 34469, None), shuffleId=40, mapIndex=14, mapId=15113, reduceId=3, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat scala.collection.Iterator.isEmpty(Iterator.scala:387)\n",
      "\tat scala.collection.Iterator.isEmpty$(Iterator.scala:387)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.isEmpty(WholeStageCodegenExec.scala:757)\n",
      "\tat org.apache.spark.sql.execution.python.FlatMapGroupsInPandasExec.$anonfun$doExecute$1(FlatMapGroupsInPandasExec.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 5), which maintains the block data to fetch is dead.\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:136)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "2022-04-10 13:11:26,994 WARN scheduler.TaskSetManager: Lost task 20.0 in stage 144.2 (TID 15440) (bdse42.example.com executor 15): FetchFailed(BlockManagerId(5, bdse75.example.com, 34469, None), shuffleId=40, mapIndex=14, mapId=15113, reduceId=47, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat scala.collection.Iterator.isEmpty(Iterator.scala:387)\n",
      "\tat scala.collection.Iterator.isEmpty$(Iterator.scala:387)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.isEmpty(WholeStageCodegenExec.scala:757)\n",
      "\tat org.apache.spark.sql.execution.python.FlatMapGroupsInPandasExec.$anonfun$doExecute$1(FlatMapGroupsInPandasExec.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 5), which maintains the block data to fetch is dead.\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:136)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.start(RetryingBlockTransferor.java:133)\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:146)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:362)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.send$1(ShuffleBlockFetcherIterator.scala:1135)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:1127)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:1000)\n",
      "\t... 29 more\n",
      "\n",
      ")\n",
      "2022-04-10 13:12:02,544 WARN scheduler.TaskSetManager: Lost task 28.0 in stage 144.2 (TID 15434) (bdse108.example.com executor 14): FetchFailed(BlockManagerId(5, bdse75.example.com, 34469, None), shuffleId=40, mapIndex=8, mapId=14272, reduceId=55, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat scala.collection.Iterator.isEmpty(Iterator.scala:387)\n",
      "\tat scala.collection.Iterator.isEmpty$(Iterator.scala:387)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.isEmpty(WholeStageCodegenExec.scala:757)\n",
      "\tat org.apache.spark.sql.execution.python.FlatMapGroupsInPandasExec.$anonfun$doExecute$1(FlatMapGroupsInPandasExec.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 5), which maintains the block data to fetch is dead.\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:136)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "2022-04-10 13:12:03,964 WARN scheduler.TaskSetManager: Lost task 11.0 in stage 144.2 (TID 15435) (bdse90.example.com executor 18): FetchFailed(BlockManagerId(5, bdse75.example.com, 34469, None), shuffleId=40, mapIndex=16, mapId=15061, reduceId=30, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat scala.collection.Iterator.isEmpty(Iterator.scala:387)\n",
      "\tat scala.collection.Iterator.isEmpty$(Iterator.scala:387)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.isEmpty(WholeStageCodegenExec.scala:757)\n",
      "\tat org.apache.spark.sql.execution.python.FlatMapGroupsInPandasExec.$anonfun$doExecute$1(FlatMapGroupsInPandasExec.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 5), which maintains the block data to fetch is dead.\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:136)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.start(RetryingBlockTransferor.java:133)\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:146)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:362)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.send$1(ShuffleBlockFetcherIterator.scala:1135)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:1127)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:1000)\n",
      "\t... 29 more\n",
      "\n",
      ")\n",
      "2022-04-10 13:12:20,872 ERROR cluster.YarnScheduler: Lost executor 5 on bdse75.example.com: Container from a bad node: container_e46_1649562268781_0008_01_000006 on host: bdse75.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:11:47.662]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:12:00.627]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:12:02.195]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:12:20,873 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 5 for reason Container from a bad node: container_e46_1649562268781_0008_01_000006 on host: bdse75.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:11:47.662]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:12:00.627]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:12:02.195]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:12:20,873 WARN scheduler.TaskSetManager: Lost task 11.0 in stage 144.1 (TID 15131) (bdse75.example.com executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000006 on host: bdse75.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:11:47.662]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:12:00.627]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:12:02.195]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:12:20,874 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 144.1 (TID 15121) (bdse75.example.com executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000006 on host: bdse75.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:11:47.662]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:12:00.627]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:12:02.195]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:13:15,251 WARN scheduler.TaskSetManager: Lost task 5.0 in stage 144.2 (TID 15431) (bdse74.example.com executor 16): FetchFailed(BlockManagerId(5, bdse75.example.com, 34469, None), shuffleId=40, mapIndex=14, mapId=15113, reduceId=18, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat scala.collection.Iterator.isEmpty(Iterator.scala:387)\n",
      "\tat scala.collection.Iterator.isEmpty$(Iterator.scala:387)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.isEmpty(WholeStageCodegenExec.scala:757)\n",
      "\tat org.apache.spark.sql.execution.python.FlatMapGroupsInPandasExec.$anonfun$doExecute$1(FlatMapGroupsInPandasExec.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 5), which maintains the block data to fetch is dead.\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:136)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.start(RetryingBlockTransferor.java:133)\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:146)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:362)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.send$1(ShuffleBlockFetcherIterator.scala:1135)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:1127)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:1000)\n",
      "\t... 29 more\n",
      "\n",
      ")\n",
      "2022-04-10 13:14:49,498 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 143.5 (TID 15510) (bdse106.example.com executor 1): FetchFailed(BlockManagerId(9, bdse93.example.com, 41999, None), shuffleId=36, mapIndex=131, mapId=14732, reduceId=69, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage30.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage30.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage32.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:778)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 9), which maintains the block data to fetch is dead.\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:136)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.lambda$initiateRetry$0(RetryingBlockTransferor.java:184)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "\t... 1 more\n",
      "\n",
      ")\n",
      "2022-04-10 13:15:02,236 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 9 for reason Container from a bad node: container_e46_1649562268781_0008_01_000010 on host: bdse93.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:14:51.483]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:14:55.328]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:14:56.201]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:15:02,236 ERROR cluster.YarnScheduler: Lost executor 9 on bdse93.example.com: Container from a bad node: container_e46_1649562268781_0008_01_000010 on host: bdse93.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:14:51.483]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:14:55.328]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:14:56.201]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:15:02,237 WARN scheduler.TaskSetManager: Lost task 9.0 in stage 144.1 (TID 15123) (bdse93.example.com executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000010 on host: bdse93.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:14:51.483]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:14:55.328]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:14:56.201]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:15:02,237 WARN scheduler.TaskSetManager: Lost task 13.0 in stage 144.1 (TID 15132) (bdse93.example.com executor 9): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000010 on host: bdse93.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:14:51.483]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:14:55.328]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:14:56.201]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:25:37,530 WARN scheduler.TaskSetManager: Lost task 5.0 in stage 144.1 (TID 15114) (bdse109.example.com executor 13): TaskCommitDenied (Driver denied task commit) for job: 144, partition: 5, attemptNumber: 0\n",
      "2022-04-10 13:26:51,345 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 16 for reason Container from a bad node: container_e46_1649562268781_0008_01_000017 on host: bdse74.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:25:10.630]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:25:10.656]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:25:11.036]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:26:51,345 ERROR cluster.YarnScheduler: Lost executor 16 on bdse74.example.com: Container from a bad node: container_e46_1649562268781_0008_01_000017 on host: bdse74.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:25:10.630]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:25:10.656]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:25:11.036]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:26:51,346 WARN scheduler.TaskSetManager: Lost task 17.0 in stage 144.3 (TID 16152) (bdse74.example.com executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000017 on host: bdse74.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:25:10.630]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:25:10.656]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:25:11.036]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:26:51,346 WARN scheduler.TaskSetManager: Lost task 18.0 in stage 144.3 (TID 16157) (bdse74.example.com executor 16): ExecutorLostFailure (executor 16 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000017 on host: bdse74.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:25:10.630]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:25:10.656]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:25:11.036]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:26:51,347 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 15 for reason Container from a bad node: container_e46_1649562268781_0008_01_000016 on host: bdse42.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:25:20.471]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:25:20.495]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:25:20.658]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:26:51,347 ERROR cluster.YarnScheduler: Lost executor 15 on bdse42.example.com: Container from a bad node: container_e46_1649562268781_0008_01_000016 on host: bdse42.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:25:20.471]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:25:20.495]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:25:20.658]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:26:51,348 WARN scheduler.TaskSetManager: Lost task 35.0 in stage 144.2 (TID 15441) (bdse42.example.com executor 15): ExecutorLostFailure (executor 15 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000016 on host: bdse42.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:25:20.471]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:25:20.495]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:25:20.658]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:26:51,348 WARN scheduler.TaskSetManager: Lost task 1.0 in stage 144.3 (TID 16148) (bdse42.example.com executor 15): ExecutorLostFailure (executor 15 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000016 on host: bdse42.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:25:20.471]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:25:20.495]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:25:20.658]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:26:58,917 WARN scheduler.TaskSetManager: Lost task 17.1 in stage 144.3 (TID 16165) (bdse74.example.com executor 22): FetchFailed(null, shuffleId=40, mapIndex=-1, mapId=-1, reduceId=48, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 40 partition 48\n",
      "\tat org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1619)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1566)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1565)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1565)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1230)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1192)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "2022-04-10 13:26:58,920 WARN scheduler.TaskSetManager: Lost task 18.1 in stage 144.3 (TID 16164) (bdse74.example.com executor 22): FetchFailed(null, shuffleId=40, mapIndex=-1, mapId=-1, reduceId=49, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 40 partition 49\n",
      "\tat org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1619)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1566)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1565)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1565)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1230)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1192)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "2022-04-10 13:26:58,922 ERROR datasources.FileFormatWriter: Aborting job c341233b-8787-481b-a2f1-23b6e5038b64.\n",
      "org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 144 (parquet at NativeMethodAccessorImpl.java:0) has failed the maximum allowable number of times: 4. Most recent failure reason:\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 40 partition 48\n",
      "\tat org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1619)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1566)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1565)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1565)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1230)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1192)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1843)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2639)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:218)\n",
      "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n",
      "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:110)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:110)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:106)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:106)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:93)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:91)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:128)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:781)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "2022-04-10 13:26:58,962 WARN scheduler.TaskSetManager: Lost task 29.0 in stage 144.3 (TID 16166) (bdse74.example.com executor 22): FetchFailed(null, shuffleId=40, mapIndex=-1, mapId=-1, reduceId=61, message=\n",
      "org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 40 partition 61\n",
      "\tat org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1619)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1566)\n",
      "\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1565)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1565)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1230)\n",
      "\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1192)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n",
      "\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n",
      "\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n",
      "\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      ")\n",
      "[Stage 144:>             (0 + 13) / 153][Stage 144:>              (1 + 5) / 158]\r"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o4917.parquet.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.jobAbortedError(QueryExecutionErrors.scala:496)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:251)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:110)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:110)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:106)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:106)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:93)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:91)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:128)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:781)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 144 (parquet at NativeMethodAccessorImpl.java:0) has failed the maximum allowable number of times: 4. Most recent failure reason:\norg.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 40 partition 48\n\tat org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1619)\n\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1566)\n\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1565)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1565)\n\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1230)\n\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1192)\n\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)\n\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1843)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2639)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:218)\n\t... 42 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(TRAIN_PERIOD)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124m    ==================================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124m    ===== results.rdd.getNumPartitions() = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults\u001b[38;5;241m.\u001b[39mrdd\u001b[38;5;241m.\u001b[39mgetNumPartitions()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===========\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124m    ==================================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124m    ==================================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124m    ===== 6. Save result table to parquet ============\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124m    ==================================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/user/HM_parquet/SVD_model/params/para\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mTRAIN_PERIOD\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124m    ==================================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124m    =====================  存檔完成 ===================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124m    ==================================================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py:885\u001b[0m, in \u001b[0;36mDataFrameWriter.parquet\u001b[0;34m(self, path, mode, partitionBy, compression)\u001b[0m\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartitionBy(partitionBy)\n\u001b[1;32m    884\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression)\n\u001b[0;32m--> 885\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o4917.parquet.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.jobAbortedError(QueryExecutionErrors.scala:496)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:251)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:186)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:113)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:111)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.executeCollect(commands.scala:125)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:110)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:110)\n\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:106)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:82)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:481)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:30)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:457)\n\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:106)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:93)\n\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:91)\n\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:128)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:848)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:382)\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:355)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:239)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:781)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: ResultStage 144 (parquet at NativeMethodAccessorImpl.java:0) has failed the maximum allowable number of times: 4. Most recent failure reason:\norg.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 40 partition 48\n\tat org.apache.spark.MapOutputTracker$.validateStatus(MapOutputTracker.scala:1619)\n\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10(MapOutputTracker.scala:1566)\n\tat org.apache.spark.MapOutputTracker$.$anonfun$convertMapStatuses$10$adapted(MapOutputTracker.scala:1565)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat org.apache.spark.MapOutputTracker$.convertMapStatuses(MapOutputTracker.scala:1565)\n\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorIdImpl(MapOutputTracker.scala:1230)\n\tat org.apache.spark.MapOutputTrackerWorker.getMapSizesByExecutorId(MapOutputTracker.scala:1192)\n\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:140)\n\tat org.apache.spark.shuffle.ShuffleManager.getReader(ShuffleManager.scala:63)\n\tat org.apache.spark.shuffle.ShuffleManager.getReader$(ShuffleManager.scala:57)\n\tat org.apache.spark.shuffle.sort.SortShuffleManager.getReader(SortShuffleManager.scala:73)\n\tat org.apache.spark.sql.execution.ShuffledRowRDD.compute(ShuffledRowRDD.scala:208)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2454)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2403)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2402)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2402)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1843)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2639)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2584)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2573)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2214)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:218)\n\t... 42 more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 13:27:14,442 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 144.2 (TID 15429) (bdse106.example.com executor 1): org.apache.spark.SparkException: Task failed while writing rows.\n",
      "\tat org.apache.spark.sql.errors.QueryExecutionErrors$.taskFailedWhileWritingRowsError(QueryExecutionErrors.scala:500)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:321)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$16(FileFormatWriter.scala:229)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): File does not exist: /user/HM_parquet/SVD_model/params/para60.parquet/_temporary/0/_temporary/attempt_202204101235337335937903251227352_0144_m_000002_15429/part-00002-7f7a1038-cd87-465c-85ba-eee6d0013f87-c000.snappy.parquet (inode 29921) Holder DFSClient_NONMAPREDUCE_-1772670830_29 does not have any open files.\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:3053)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.completeFileInternal(FSDirWriteFileOp.java:704)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.completeFile(FSDirWriteFileOp.java:690)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:3097)\n",
      "\tat org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:970)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:639)\n",
      "\tat org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:600)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:568)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:552)\n",
      "\tat org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)\n",
      "\tat org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)\n",
      "\tat java.security.AccessController.doPrivileged(Native Method)\n",
      "\tat javax.security.auth.Subject.doAs(Subject.java:422)\n",
      "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)\n",
      "\tat org.apache.hadoop.ipc.Server$Handler.run(Server.java:2966)\n",
      "\n",
      "\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1573)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1519)\n",
      "\tat org.apache.hadoop.ipc.Client.call(Client.java:1416)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)\n",
      "\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)\n",
      "\tat com.sun.proxy.$Proxy16.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.complete(ClientNamenodeProtocolTranslatorPB.java:570)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)\n",
      "\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)\n",
      "\tat com.sun.proxy.$Proxy17.complete(Unknown Source)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:951)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:908)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:891)\n",
      "\tat org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:846)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)\n",
      "\tat org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)\n",
      "\tat org.apache.parquet.hadoop.util.HadoopPositionOutputStream.close(HadoopPositionOutputStream.java:64)\n",
      "\tat org.apache.parquet.hadoop.ParquetFileWriter.end(ParquetFileWriter.java:1106)\n",
      "\tat org.apache.parquet.hadoop.InternalParquetRecordWriter.close(InternalParquetRecordWriter.java:132)\n",
      "\tat org.apache.parquet.hadoop.ParquetRecordWriter.close(ParquetRecordWriter.java:164)\n",
      "\tat org.apache.spark.sql.execution.datasources.parquet.ParquetOutputWriter.close(ParquetOutputWriter.scala:41)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.releaseCurrentWriter(FileFormatDataWriter.scala:64)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.releaseResources(FileFormatDataWriter.scala:75)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatDataWriter.commit(FileFormatDataWriter.scala:105)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$1(FileFormatWriter.scala:305)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1496)\n",
      "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:311)\n",
      "\t... 9 more\n",
      "\n",
      "2022-04-10 13:28:29,394 WARN scheduler.TaskSetManager: Lost task 15.0 in stage 144.2 (TID 15437) (bdse90.example.com executor 18): TaskCommitDenied (Driver denied task commit) for job: 144, partition: 34, attemptNumber: 0\n",
      "2022-04-10 13:31:36,772 WARN scheduler.TaskSetManager: Lost task 25.0 in stage 144.2 (TID 15430) (bdse108.example.com executor 14): TaskCommitDenied (Driver denied task commit) for job: 144, partition: 45, attemptNumber: 0\n",
      "2022-04-10 13:32:51,582 WARN scheduler.TaskSetManager: Lost task 21.0 in stage 144.3 (TID 16154) (bdse108.example.com executor 14): TaskCommitDenied (Driver denied task commit) for job: 144, partition: 45, attemptNumber: 0\n",
      "2022-04-10 13:33:42,921 ERROR cluster.YarnScheduler: Lost executor 8 on bdse91.example.com: Container from a bad node: container_e46_1649562268781_0008_01_000009 on host: bdse91.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:33:19.208]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:33:23.579]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:33:23.952]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:33:42,921 WARN scheduler.TaskSetManager: Lost task 8.0 in stage 144.2 (TID 15428) (bdse91.example.com executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000009 on host: bdse91.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:33:19.208]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:33:23.579]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:33:23.952]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:33:42,921 WARN scheduler.TaskSetManager: Lost task 9.0 in stage 144.2 (TID 15432) (bdse91.example.com executor 8): ExecutorLostFailure (executor 8 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000009 on host: bdse91.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:33:19.208]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:33:23.579]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:33:23.952]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:33:42,922 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 8 for reason Container from a bad node: container_e46_1649562268781_0008_01_000009 on host: bdse91.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:33:19.208]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:33:23.579]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:33:23.952]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:34:56,045 WARN scheduler.TaskSetManager: Lost task 63.0 in stage 144.3 (TID 16160) (bdse93.example.com executor 21): TaskCommitDenied (Driver denied task commit) for job: 144, partition: 88, attemptNumber: 0\n",
      "2022-04-10 13:35:56,138 WARN scheduler.TaskSetManager: Lost task 4.0 in stage 144.3 (TID 16151) (bdse109.example.com executor 13): TaskCommitDenied (Driver denied task commit) for job: 144, partition: 16, attemptNumber: 0\n",
      "2022-04-10 13:37:25,915 WARN scheduler.TaskSetManager: Lost task 2.0 in stage 144.3 (TID 16156) (bdse92.example.com executor 12): FetchFailed(BlockManagerId(8, bdse91.example.com, 40545, None), shuffleId=40, mapIndex=21, mapId=15063, reduceId=7, message=\n",
      "org.apache.spark.shuffle.FetchFailedException\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:1165)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:903)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:84)\n",
      "\tat org.apache.spark.util.CompletionIterator.next(CompletionIterator.scala:29)\n",
      "\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:31)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.sort_addToSorter_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage33.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:759)\n",
      "\tat scala.collection.Iterator.isEmpty(Iterator.scala:387)\n",
      "\tat scala.collection.Iterator.isEmpty$(Iterator.scala:387)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.isEmpty(WholeStageCodegenExec.scala:757)\n",
      "\tat org.apache.spark.sql.execution.python.FlatMapGroupsInPandasExec.$anonfun$doExecute$1(FlatMapGroupsInPandasExec.scala:81)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1462)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "Caused by: org.apache.spark.ExecutorDeadException: The relative remote executor(Id: 8), which maintains the block data to fetch is dead.\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService$$anon$2.createAndStart(NettyBlockTransferService.scala:136)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.transferAllOutstanding(RetryingBlockTransferor.java:154)\n",
      "\tat org.apache.spark.network.shuffle.RetryingBlockTransferor.start(RetryingBlockTransferor.java:133)\n",
      "\tat org.apache.spark.network.netty.NettyBlockTransferService.fetchBlocks(NettyBlockTransferService.scala:146)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.sendRequest(ShuffleBlockFetcherIterator.scala:362)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.send$1(ShuffleBlockFetcherIterator.scala:1135)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchUpToMaxBytes(ShuffleBlockFetcherIterator.scala:1127)\n",
      "\tat org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:1000)\n",
      "\t... 29 more\n",
      "\n",
      ")\n",
      "2022-04-10 13:38:03,483 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 144.3 (TID 16150) (bdse106.example.com executor 1): TaskCommitDenied (Driver denied task commit) for job: 144, partition: 2, attemptNumber: 0\n",
      "2022-04-10 13:38:25,315 ERROR cluster.YarnScheduler: Lost executor 20 on bdse75.example.com: Container from a bad node: container_e46_1649562268781_0008_01_000021 on host: bdse75.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:38:18.397]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:38:18.747]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:38:18.808]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:38:25,315 WARN scheduler.TaskSetManager: Lost task 23.0 in stage 144.3 (TID 16159) (bdse75.example.com executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000021 on host: bdse75.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:38:18.397]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:38:18.747]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:38:18.808]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:38:25,316 WARN scheduler.TaskSetManager: Lost task 12.0 in stage 144.3 (TID 16155) (bdse75.example.com executor 20): ExecutorLostFailure (executor 20 exited caused by one of the running tasks) Reason: Container from a bad node: container_e46_1649562268781_0008_01_000021 on host: bdse75.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:38:18.397]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:38:18.747]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:38:18.808]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:38:25,316 WARN cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 20 for reason Container from a bad node: container_e46_1649562268781_0008_01_000021 on host: bdse75.example.com. Exit status: 137. Diagnostics: [2022-04-10 13:38:18.397]Container killed on request. Exit code is 137\n",
      "[2022-04-10 13:38:18.747]Container exited with a non-zero exit code 137. \n",
      "[2022-04-10 13:38:18.808]Killed by external signal\n",
      ".\n",
      "2022-04-10 13:38:55,373 WARN scheduler.TaskSetManager: Lost task 11.0 in stage 144.3 (TID 16158) (bdse89.example.com executor 19): TaskCommitDenied (Driver denied task commit) for job: 144, partition: 34, attemptNumber: 0\n",
      "2022-04-10 13:39:56,582 WARN scheduler.TaskSetManager: Lost task 3.0 in stage 144.3 (TID 16149) (bdse90.example.com executor 18): TaskCommitDenied (Driver denied task commit) for job: 144, partition: 15, attemptNumber: 0\n",
      "2022-04-10 13:40:11,835 WARN scheduler.TaskSetManager: Lost task 27.0 in stage 144.3 (TID 16162) (bdse109.example.com executor 13): TaskCommitDenied (Driver denied task commit) for job: 144, partition: 52, attemptNumber: 0\n",
      "2022-04-10 13:43:58,908 WARN scheduler.TaskSetManager: Lost task 6.0 in stage 144.3 (TID 16153) (bdse89.example.com executor 19): TaskCommitDenied (Driver denied task commit) for job: 144, partition: 20, attemptNumber: 0\n",
      "2022-04-10 13:45:33,922 WARN scheduler.TaskSetManager: Lost task 26.0 in stage 144.3 (TID 16163) (bdse92.example.com executor 12): TaskCommitDenied (Driver denied task commit) for job: 144, partition: 51, attemptNumber: 0\n",
      "2022-04-10 13:56:02,486 WARN scheduler.TaskSetManager: Lost task 69.0 in stage 144.3 (TID 16161) (bdse93.example.com executor 21): TaskCommitDenied (Driver denied task commit) for job: 144, partition: 94, attemptNumber: 0\n"
     ]
    }
   ],
   "source": [
    "main(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cb85fe-1e56-45ac-9d3f-91c5f2f17285",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8fcf28-fd19-474e-b036-fc5469c49fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d82863-2fc0-493e-874f-46117ba3134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3867838-c662-4aeb-8e31-76eff51e97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(360)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4530d571-1233-4348-b9f0-c5f4212fc033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
